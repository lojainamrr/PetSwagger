Ø£ÙƒÙŠØ¯! Ø¯Ù‡ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù„ÙŠ ØªØ­Ø·Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ Ù…Ù„Ù README.md:

# ğŸ¾ Petstore API Testing Project

Welcome to our *API testing project* for the [Swagger Petstore API](https://petstore.swagger.io/#/), designed using *Postman*. This project demonstrates professional API testing practices including:

- Comprehensive test case design  
- Structured bug tracking  
- Collaborative workflow  
- Clear and accessible documentation

---

## ğŸ‘¥ Team Members

- *Ahmed Saad* â€“ Software Tester
- *Lojain Amr* â€“ Software Tester

---

## ğŸ“‚ Project Structure

petstore-api-testing/ â”‚ â”œâ”€â”€ Postman/         # Postman collections & environments â”œâ”€â”€ Reports/         # Test cases and bug tracking (Excel) â”œâ”€â”€ Attachments/     # Screenshots and supporting files â””â”€â”€ README.md        # Project documentation

---

## ğŸ›  Tools & Technologies

- *Postman* â€“ API testing and automation  
- *Swagger UI* â€“ API documentation & interface ([Petstore API](https://petstore.swagger.io/#/))  
- *Microsoft Excel* â€“ Test case and bug report documentation  
- *GitHub* â€“ Version control and project sharing

---

## âœ… Project Workflow

### 1. Test Planning & Design  
- Reviewed all endpoints provided by the Petstore API  
- Designed detailed test cases for CRUD operations (POST, GET, PUT, DELETE)  
- Included edge cases, boundary values, and negative scenarios

### 2. Postman Collection Setup  
- Created modular, folder-based collections  
- Utilized environments and variables for flexibility  
- Added *test scripts* to validate:
  - Status codes  
  - Response body and structure  
  - Headers and response time

### 3. Test Execution  
- Ran tests manually and using Postman's *Collection Runner*  
- Captured evidence (screenshots) for failed test cases  
- Tracked results with clear pass/fail indicators

### 4. Bug Reporting  
- Identified and logged API issues  
- Documented bugs with:
  - Clear summary  
  - Steps to reproduce  
  - Expected vs actual behavior  
  - Severity and priority labels

---

## ğŸ” Sample Tested Scenarios

- POST /pet â€“ Add a new pet with valid payload  
- GET /pet/{petId} â€“ Retrieve pet by valid and invalid ID  
- PUT /pet â€“ Update pet details  
- DELETE /pet/{petId} â€“ Remove pet from system  
- Negative scenarios:
  - Invalid IDs
  - Missing required fields
  - Incorrect data types

---

## ğŸ“ˆ Reports

All reports are available in the Reports/ directory:

- *TestCasesReport.xlsx*  
  - Test ID  
  - Endpoint  
  - Input data  
  - Expected & actual results  
  - Test status (Pass/Fail)

- *BugsReport.xlsx*  
  - Bug ID  
  - Description  
  - Reproduction steps  
  - Expected vs actual behavior  
  - Severity & priority

---

## ğŸ–¼ Attachments

Stored in Attachments/:
- Screenshots of failed test executions  
- Visual evidence for reported bugs  

---



Ù„Ùˆ Ø­Ø§Ø¨Ø¨ Ø£Ø¶ÙŠÙ Ø±Ø§Ø¨Ø· GitHub Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ø¯Ù„ your-username Ø£Ùˆ ØªØ¶ÙŠÙ Ù‚Ø³Ù… "Future Work" Ø£Ùˆ "Challenges Faced" Ù‚ÙˆÙ„ÙŠ.
